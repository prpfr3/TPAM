import requests
from bs4 import BeautifulSoup
import csv, os

DATAIO_DIR = os.path.join("D:\\Data", "TPAM")
OUTPUTFILE = "Depots_Wikipedia_Links_2023-11-21.csv"


def extract_table_data(wikipedia_url):
    # Send an HTTP request to the Wikipedia page
    response = requests.get(wikipedia_url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the HTML content of the page using BeautifulSoup
        soup = BeautifulSoup(response.text, "html.parser")

        # Find the first table in the page
        table = soup.find("table")

        # Check if a table is found
        if table:
            # Open a CSV file for writing
            with open(
                os.path.join(DATAIO_DIR, "OUTPUTFILE"),
                "w",
                newline="",
                encoding="utf-8",
            ) as csvfile:
                # Create a CSV writer
                csv_writer = csv.writer(csvfile)

                # Write the header row to the CSV file
                csv_writer.writerow(["Value", "URL"])

                # Iterate over the rows of the table
                for row in table.find_all("tr"):
                    # Find all cells in the row
                    cells = row.find_all(["td", "th"])

                    # Check if the row has at least three cells (to avoid index errors)
                    if len(cells) >= 3:
                        # Extract values with URL links only from the third column
                        value_cell = cells[2]
                        link = value_cell.find("a")

                        if link:
                            value = link.text.strip()
                            url = link.get("href")

                            # Write the value and URL to the CSV file
                            csv_writer.writerow([value, url])

            print("Extraction and writing to CSV file successful.")
        else:
            print("No table found on the Wikipedia page.")
    else:
        print(
            f"Failed to retrieve the Wikipedia page. Status Code: {response.status_code}"
        )


# Example usage
wikipedia_url = "https://en.wikipedia.org/wiki/List_of_British_Railways_shed_codes"
extract_table_data(wikipedia_url)
